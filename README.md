# ULoRA
ULoRA:  Explanation-Enhanced Federated Fine-Tuning of Large Language Models for Photovoltaic Power Forecasting

This repository contains the official implementation and datasets for the paper:

Explanation-Enhanced Federated Fine-Tuning of Large Language Models for Photovoltaic Power Forecasting

Overview

We propose ULoRA-FL, a noise-free federated LoRA fine-tuning framework for short-term photovoltaic (PV) power forecasting. Our approach addresses the aggregation noise issue in federated learning and demonstrates superior convergence and predictive performance compared to existing methods.

Features

Full pipeline for federated fine-tuning of large language models (LLMs) using the ULoRA method

Support for training, evaluation, and benchmarking

In this paper, we conducted the comparison with state-of-the-art forecasting methods: TimeXer, iTransformer, SVM, ANN, KNN, full model fine-tuning, FLoRA, and FedAvg

Code and Public datasets from three PV stations in Australiaï¼Œas shown in prompts in this project
